CassiopeiaBot is a Open Source HTTP/1.1 Text Web Crawler for Linux.

It is a fork of the WIRE-Nic open source project which is itself a fork of the WIRE open source project
(Web Information Retrieval Environment) that was developed by Center for Web Research from University of Chile.
More information about it can be found at  http://www.cwr.cl/projects/WIRE/ and https://sourceforge.net/projects/wire-nic/.

It has been customized to be a selective crawler for geographical area (Sardinia - Italy -) but it is also possible to make it behave differently.
Before proceeding with the development of CassiopeiaBot, all possible bug fixes were applied to the software and for technical reasons some features have been disabled from the original project.

Here are the new features:
• Multithreading.
• Object-oriented C++ language.
• HTTPS protocol and HTTP compression.
• Support to UTF-8 multibyte characters.
• Parsing of PDF, FEED/ATOM and FEED/RSS.
• Language detection and appropriate word stemming.
• Analysis of sitemap files written in RDF/XML format.
• Thematic (IT) detection of web pages in order to assign an appropriate score.
• Interactive console cbot-info-shell with auto-complete function to consult crawler metadata and plain text of downloaded web pages.

List of some improvements or changes.
• Improvements for "Chunked Transfer Encoding".
• C-Ares libray https://c-ares.org/ in place of ADNS.
• Strict control of URL rewrite loops during downloads.
• Gatherer process "integrated" into the Harvester process.
• Improvements for correct interpretation of robots TXT/RDF/XML files.
• More score and frequent downloads of constantly updated web pages (EN/IT).
• Domain names and keywords split only if the result is related to the document content.
• Less relevance to web documents that contain many hypertext links in the face of little content.
• Converting of the internal indexes (Linear Probing) and data storages from single to distributed in order to work in multithread.
• Text analysis to send at the search engine the terms with a different score according the type of html tags in which they are enclosed.
• Html4 parser convert downloaded web pages into plain text, in order to greatly increase the overall performance of the search engine by reducing storage space.
• Connector use SQL language for realtime indexes of the OpenSource C++ Sphinx (https://sphinxsearch.com/) or Manticore (https://manticoresearch.com/) Search Engines.
• By introducing the concept of DomainId, the Pagerank and Siterank (multithreaded) algorithms respectively reduce the score of pages and sites reached through the same second-level domain in order to improve the quality of search engine results.

The code was developed always using tools like Gdb and Valgrind to avoid making mistakes like:
- memory leaks
- dangling pointers
- buffer overflow

The project was discontinued in 2017 but successfully tested several times until 2016 under a Fedora 23 distro, unfortunately there was no time to add features reported in the TODO file.

CassiopeiaBot has been optimized to search almost exclusively for sites in Sardinia, so don't be surprised if you find terms like sardinia, shardana, nuraghe and so on.
It will be necessary to dedicate oneself to update some parts of the code to the new libraries and integrate the new functions according to the changes in the WEB that have taken place in recent years.
 
Marco <workwheat09@gmail.com>
